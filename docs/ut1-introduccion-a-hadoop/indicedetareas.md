# Índice de prácticas y tareas

Este índice incluye todas las prácticas guiadas y tareas correspondientes al curso. Asegúrate de seguir las instrucciones cuidadosamente para cada práctica y tarea, y consulta los materiales de apoyo cuando sea necesario.

## Prácticas guiadas

Las prácticas guiadas están diseñadas para que sigas un conjunto de instrucciones paso a paso y te familiarices con el entorno y las herramientas utilizadas en Big Data. Cada práctica cubre un aspecto clave del entorno de Hadoop y su ecosistema.

1. [**Práctica Instalación Hadoop Single Node**](/site/bda-apuntes/ut1-introduccion-a-hadoop/tareas/hadoop/1instalacionhadoop)
    - **Descripción:** Esta práctica cubre el proceso de instalación de Hadoop en un entorno de un solo nodo. El objetivo es configurar un clúster Hadoop básico en modo pseudo-distribuido en tu máquina local.
    - **Objetivos:** 
        - Configurar Hadoop en un único nodo.
        - Ejecutar comandos básicos de HDFS.
        - Verificar la instalación utilizando los servicios de Hadoop.
   
2. [**Práctica Inicial HDFS**](/site/bda-apuntes/ut1-introduccion-a-hadoop/tareas/hadoop/hdfs/1practicainicial)
    - **Descripción:** Esta práctica introduce el sistema de archivos distribuido de Hadoop (HDFS). Aprenderás a subir y descargar archivos en el sistema y a utilizar comandos básicos para manipular los datos.
    - **Objetivos:** 
        - Subir, descargar y listar archivos en HDFS.
        - Utilizar comandos esenciales como `hdfs dfs -put`, `hdfs dfs -get`, y `hdfs dfs -ls`.
        - Verificar la replicación de los bloques y la ubicación de los archivos en HDFS.


## Tareas

Las tareas son ejercicios que complementan las prácticas guiadas y tienen como objetivo reforzar los conocimientos adquiridos. Algunas tareas requerirán investigación adicional y la implementación de soluciones más avanzadas.

1. [**Introducción al Big Data**](/site/bda-apuntes/ut1-introduccion-a-hadoop/tareas/1tareaintroductoria)
    - **Descripción:** Esta tarea introductoria cubre los conceptos clave de Big Data, sus desafíos, y las tecnologías fundamentales en el ecosistema Hadoop.
    - **Objetivos:**
        - Definir Big Data y sus características (volumen, velocidad, variedad, etc.).
        - Explicar la importancia de Hadoop en el procesamiento de grandes volúmenes de datos.
        - Realizar una breve investigación sobre casos de uso de Big Data en la industria.
