# Gu√≠a para configurar un cl√∫ster Hadoop usando Docker y Docker-compose üöÄ

### 1. **Instalar Docker**

Docker es una plataforma que permite aislar aplicaciones en contenedores, facilitando su portabilidad y replicabilidad en distintos entornos. Para instalar Docker, sigue estos pasos:

Si ves que Docker est√° corriendo, ¬°est√°s listo! ü•≥

### 2. **Instalar Docker-compose**

Docker-compose es una herramienta que permite orquestar m√∫ltiples contenedores con un solo archivo de configuraci√≥n. Para instalar Docker-compose, ejecuta:

¬°Con Docker y Docker-compose instalados, ya est√°s listo para crear un cl√∫ster Hadoop! üéâ

---

### 3. **Crear el archivo docker-compose.yml**

Este archivo definir√° los servicios necesarios para ejecutar Hadoop (como NameNode y DataNode). Aqu√≠ te dejo un ejemplo:

```yaml
version: '3'
services:
  namenode:
    image: hadoop:latest
    container_name: namenode
    hostname: namenode
    ports:
      - "9870:9870" # Web UI
      - "9000:9000" # RPC
    volumes:
      - ./hadoop_config:/opt/hadoop/etc/hadoop
      - namenode_data:/opt/hadoop/data/nameNode
    networks:
      - hadoop_network

  datanode:
    image: hadoop:latest
    container_name: datanode
    hostname: datanode
    ports:
      - "9864:9864" # Web UI
    volumes:
      - ./hadoop_config:/opt/hadoop/etc/hadoop
      - datanode_data:/opt/hadoop/data/dataNode
    networks:
      - hadoop_network

networks:
  hadoop_network:

volumes:
  namenode_data:
  datanode_data:
```

Este archivo configura dos servicios:
- **NameNode**: encargado de gestionar el sistema de archivos y la informaci√≥n de los bloques de datos.
- **DataNode**: responsable de almacenar los bloques de datos.

---

### 4. **Crear los archivos de configuraci√≥n de Hadoop**

#### 4.1 **Crear `core-site.xml`**

El archivo `core-site.xml` contiene configuraciones b√°sicas de Hadoop, como la direcci√≥n del sistema de archivos (HDFS) y algunas pol√≠ticas.

```xml
<configuration>
   <property>
      <name>fs.defaultFS</name>
      <value>hdfs://namenode:9000</value> <!-- URL del NameNode -->
   </property>

   <property>
      <name>dfs.replication</name>
      <value>1</value> <!-- N√∫mero de r√©plicas de cada bloque -->
   </property>

   <property>
      <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
      <value>false</value> <!-- Deshabilitar la verificaci√≥n de IP y nombre de host -->
   </property>

   <property>
      <name>dfs.namenode.rpc-address</name>
      <value>namenode:9000</value> <!-- Direcci√≥n de RPC del NameNode -->
   </property>

   <property>
      <name>dfs.permissions.enabled</name>
      <value>false</value> <!-- Deshabilitar las verificaciones de permisos -->
   </property>

   <property>
      <name>ipc.client.connect.max.retries</name>
      <value>10</value> <!-- N√∫mero de intentos de reconexi√≥n del cliente -->
   </property>

   <property>
      <name>ipc.client.connect.retry.interval</name>
      <value>1000</value> <!-- Intervalo entre intentos de reconexi√≥n (ms) -->
   </property>
</configuration>
```

Este archivo configura el sistema de archivos y algunas propiedades de conectividad y permisos.

---

#### 4.2 **Crear `hdfs-site.xml`**

Este archivo define c√≥mo se gestionan los datos en el HDFS. Incluye la configuraci√≥n de los directorios de almacenamiento y el tama√±o de los bloques.

```xml
<configuration>
   <property>
      <name>dfs.replication</name>
      <value>1</value> <!-- N√∫mero de r√©plicas por bloque -->
   </property>

   <property>
      <name>dfs.namenode.name.dir</name>
      <value>file:///opt/hadoop/data/nameNode</value> <!-- Directorio del NameNode -->
   </property>

   <property>
      <name>dfs.datanode.data.dir</name>
      <value>file:///opt/hadoop/data/dataNode</value> <!-- Directorio del DataNode -->
   </property>

   <property>
      <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
      <value>false</value> <!-- Deshabilitar la verificaci√≥n de IP y nombre de host -->
   </property>

   <property>
      <name>dfs.permissions.enabled</name>
      <value>false</value> <!-- Deshabilitar las verificaciones de permisos -->
   </property>

   <property>
      <name>dfs.namenode.handler.count</name>
      <value>10</value> <!-- N√∫mero de manejadores de peticiones del NameNode -->
   </property>

   <property>
      <name>dfs.blocksize</name>
      <value>134217728</value> <!-- Tama√±o del bloque: 128MB -->
   </property>
</configuration>
```

Este archivo define c√≥mo se manejan los bloques de datos y d√≥nde se almacenan tanto en el NameNode como en el DataNode.

---

### 5. **Crear el script `start-hdfs.sh`**

Este script se asegura de que el NameNode est√© formateado antes de iniciar el servicio.

```bash
#!/bin/bash
if [ ! -d "/opt/hadoop/data/nameNode/current" ]; then
    echo "Formatting NameNode..."
    hdfs namenode -format
fi
hdfs namenode
```

- Si el NameNode a√∫n no ha sido formateado, lo har√°.
- Luego inicia el servicio `namenode`.

---

### 6. **Crear el script `init-datanode.sh`**

Este script limpia los datos antiguos del DataNode y configura los permisos necesarios.

```bash
#!/bin/bash
rm -rf /opt/hadoop/data/dataNode/*
chown -R hadoop:hadoop /opt/hadoop/data/dataNode
chmod 755 /opt/hadoop/data/dataNode
hdfs datanode
```

- Elimina cualquier dato antiguo en el directorio del DataNode.
- Establece los permisos correctos.
- Finalmente, inicia el servicio `datanode`.

---

### üéØ **Conclusi√≥n**

Con estos pasos, has creado un cl√∫ster de Hadoop utilizando Docker y Docker-compose. Esta configuraci√≥n te permite simular un entorno de cl√∫ster de Hadoop completamente funcional en tu m√°quina local. üéâ

Ahora, solo resta ejecutar:

```bash
docker-compose up
```

Y tu cl√∫ster de Hadoop estar√° en funcionamiento. ¬°Listo para procesar grandes vol√∫menes de datos!